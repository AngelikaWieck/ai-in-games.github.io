<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <link rel="stylesheet" href="style.css" />
  <title>KI & Spiele</title>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

  <script>
    const answers = [7, 7, 4, 5];
    const reviewExercise1 = () => {
      for (let i = 0; i < answers.length; i++) {
        if (document.getElementById(i + 1).value != answers[i]) {
          document.getElementById(i + 1).style.color = "red";
        } else {
          document.getElementById(i + 1).style.color = "green";
        }
      }
    }
    const answerExercise1 = () => {
      for (let i = 0; i < answers.length; i++) {
        if (document.getElementById(i + 1).value != answers[i]) {
          document.getElementById(i + 1).style.color = "red";
          document.getElementById(i + 1).value = answers[i];
        }
      }
    }
    const resetExercise1 = () => {
      for (let i = 0; i < answers.length; i++) {
        document.getElementById(i + 1).value = "";
        document.getElementById(i + 1).style.color = "black";
      }

    }


  </script>
</head>

<body>
  <h1>KI & Spiele</h1>

  <p>
    Jeden Tag fÃ¤llen wir Entscheidungen. Mal mit kleinen Konsequenzen, mal mit
    groÃŸen Konsequenzen. Mal mit Konsequenzen nur fÃ¼r uns selber, mal mit
    Konsequenzen fÃ¼r sehr viele Menschen. Mal denken wir wenig nach dabei, mal
    denken wir sehr genau nach. Aber wie kÃ¶nnen wir die besten Entscheidungen
    treffen? Die wirklich beste Entscheidung kÃ¶nnen wir natÃ¼rlich nur treffen,
    wenn wir alle Konsequenzen kennen und bewerten kÃ¶nnen. Diesen Zustand nennt
    man
    <b>Perfect Information</b>. Game Theory versucht alltÃ¤gliche Situationen auf
    abstrakte Spiele abzubilden, um dann diese gut beschreibbaren und
    handhabbaren Spiele
    genau wie bekannte Spiele wie Schach zu analysieren, und die beste
    Entscheidung zu finden. Diese Lehreinheit soll einen Ãœberblick Ã¼ber
    Entscheidungsfindung
    bei Spielen mit Perfect Information geben, und das Ganze in den Kontext von
    kÃ¼nstlicher Intelligenz bringen.
  </p>


  <h2>1. Adversarielle Suche</h2>

  <h3>
    Zero-sum-games
  </h3>
  <p>
    Eine besondere Art von Spielen sind <a
      href="https://en.wikipedia.org/wiki/Zero-sum_game"
      target="_blank"><b>Zero-sum-games</b></a>.
    Dies sind Spiele,
    bei denen
    die Summe des Ergebnisses am Ende bei jedem Spielausgang konstant ist. Wenn
    zum
    Beispiel zwei Spieler Alice und Bob Schach spielen, kann entweder Alice
    gewinnen, dann kriegt Alice 1 Punkt und Bob 0, oder Bob gewinnt, dann kriegt
    Alice 0 Punkte und Bob 1, oder es geht unentschieden aus, dann kriegt sowohl
    Alice als auch Bob $\frac{1}{2}$ Punkt. Insgesamt wird also immer genau 1
    Punkt
    verteilt.
    Wenn man sich nun noch vorstellt, dass beide Spieler $\frac{1}{2}$ Punkt als
    Einsatz
    gezahlt haben und die EinsÃ¤tze zum Ergebnis addiert, kommt man immer auf 0,
    daher der Name Zero-sum-games. Ein etwas intuitiverer Name wÃ¤re vielleicht
    constant-sum-games.
  </p>
  <h3>Minimax</h3>
  <p>
    FÃ¼r ein zwei Spieler Zero-sum-game wollen wir nun einen Algorithmus
    entwickeln,
    der das Ergebnis berechnet, wenn beide Spieler optimal spielen. DafÃ¼r
    benÃ¶tigen
    wir eine Datenstruktur, um Spiele darzustellen. Hier bietet sich ein
    gerichteter
    Baum an. Jeder Knoten reprÃ¤sentiert dann einen Spielzustand (die Wurzel den
    Ausgangszustand) und jede Kante einen legalen Spielzug. Eine Kante $s =
    (z_1, z_2)$ stellt also einen Spielzug $s$ dar, der beim Spielzustand $ğ‘§_1$
    legal ist, und nach dem der Spielzustand $ğ‘§_2$ erreicht wird. Die BlÃ¤tter
    reprÃ¤sentieren
    EndzustÃ¤nde, die das Spiel beenden und haben einen Ergebniswert, der angibt
    wie
    viele Punkte der erste Spieler an der Reihe bekommt (dieser eine Wert reicht
    aus, da durch die Zero-sum-game Bedingung auch die Punktzahl fÃ¼r den anderen
    Spieler abgeleitet werden kann). Den ersten Spieler nennen wir deshalb
    ğ‘€ğ´ğ‘‹
    (er probiert den Ergebniswert zu maximieren) und den zweiten Spieler nennen
    wir
    ğ‘€ğ¼ğ‘, da er versucht den Ergebniswert zu minimieren. Als Eingabe erhÃ¤lt
    unser
    Algorithmus also einen solchen Baum und als Ausgabe wird der Ergebniswert
    (Punktzahl vom ersten Spieler) produziert. Nach den beiden Spielern ğ‘€ğ¼ğ‘
    und
    ğ‘€ğ´ğ‘‹ nennen wir unseren Algorithmus ğ‘€ğ‘–ğ‘›ğ‘–ğ‘šğ‘ğ‘¥.
  </p>
  <br>
  <p>
    Der Algorithmus basiert auf einer <a
      href="https://de.wikipedia.org/wiki/Tiefensuche"
      target="_blank"><b>Tiefensuche</b></a>.
    FÃ¼r
    jeden Knoten,
    beginnend
    bei
    der Wurzel, wird der Ergebniswert basierend auf dem Spieler an der Reihe und
    den
    Ergebniswerten der Kindknoten basierend auf der folgenden Funktion
    berechnet:

    $$ minimax(s) =
    \begin{cases}
    min\{minimax(k) \mid k \in s.Kinder\} & s.Spieler = MIN\\
    max\{minimax(k) \mid k \in s.Kinder\} & s.Spieler = MAX\\
    \end{cases}$$


    Schon an der Definition der Funktion ist zu erkennen, dass dieser
    Algorithmus
    sehr leicht rekursiv zu implementieren ist. Alternativ kann mit Hilfe der
    topologischen Sortierung auch <a
      href="https://de.wikipedia.org/wiki/Dynamische_Programmierung"
      target="_blank">Dynamische Programmierung</a> auf dem Spielgraphen
    implementiert werden.
  </p>

  <details class="aufgabe">
    <summary>Aufgabe 1</summary>
    <div class="content">

      <p>
        Hast du den Algorithmus verstanden? Stell dir folgendes Spiel vor:
        ğ‘€ğ¼ğ‘
        hat drei
        Taschen mit je drei GeldbÃ¼ndeln verschiedener Werte. ğ‘€ğ´ğ‘‹ bekommt eins
        dieser
        GeldbÃ¼ndel von ğ‘€ğ¼ğ‘. DafÃ¼r darf ğ‘€ğ´ğ‘‹ eine der drei Taschen auswÃ¤hlen
        und
        dann darf
        ğ‘€ğ¼ğ‘ aus den drei GeldbÃ¼ndeln aus dieser Tasche auswÃ¤hlen, welches
        ğ‘€ğ´ğ‘‹
        bekommt.
        Beide Spieler wissen welche GeldbÃ¼ndel in welchen Taschen sind und wie
        viel die
        verschiedenen GeldbÃ¼ndel wert sind. Logischer Weise mÃ¶chte ğ‘€ğ´ğ‘‹
        maximieren wie
        viel Geld er bekommt, und ğ‘€ğ¼ğ‘ mÃ¶chte minimieren wie viel ğ‘€ğ´ğ‘‹
        bekommt.
        Trage im
        Spielbaum die ğ‘€ğ‘–ğ‘›ğ‘–ğ‘šğ‘ğ‘¥ Werte von jedem Knoten ein. Die grÃ¼nen
        Felder
        stellen Entscheidungen
        von <span class="green">ğ‘€ğ´ğ‘‹</span> dar, die roten die von <span
          class="red">ğ‘€ğ¼ğ‘</span>. Die Blattknoten
        stellen
        die Werte der GeldbÃ¼ndel dar.
      </p>
      <div class="center">
        <div class="tree">
          <ul>
            <li>
              <input class="green" id="1" type="text" />
              <ul>
                <li>
                  <input class="red" id="2" type="text" />
                  <ul>
                    <li>
                      <p>9</p>
                    </li>
                    <li>
                      <p>9</p>
                    </li>
                    <li>
                      <p>7</p>
                    </li>
                  </ul>
                </li>
                <li>
                  <input class="red" id="3" type="text" />
                  <ul>
                    <li>
                      <p>4</p>
                    </li>
                    <li>
                      <p>8</p>
                    </li>
                    <li>
                      <p>8</p>
                    </li>
                  </ul>
                </li>
                <li>
                  <input class="red" id="4" type="text" />
                  <ul>
                    <li>
                      <p>9</p>
                    </li>
                    <li>
                      <p>5</p>
                    </li>
                    <li>
                      <p>7</p>
                    </li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </div>
        <div>
          <button onclick="reviewExercise1()">Korrigieren</button>
          <button onclick="answerExercise1()">LÃ¶sung</button>
          <button onclick="resetExercise1()">Reset</button>
        </div>
      </div>
    </div>
  </details>

  <h3>Laufzeit von Minimax</h3>
  <p>
    Sowohl mit der rekursiven Implementierung als auch mit dynamischer
    Programmierung resultiert eine fÃ¼r die Tiefensuche gewÃ¶hnliche Laufzeit in
    $ğ‘‚(|ğ‘‰| + |ğ¸|)$. Da es in einem gerichteten Baum eine Kante weniger als
    Knoten gibt, ist das also eine Laufzeit von $ğ‘‚(|ğ‘‰|)$, also linear zur
    Anzahl der Knoten bzw. SpielzustÃ¤nde. Bei einem Spiel mit $ğ‘Ÿ$ Runden und
    jeweils $ğ‘ $ SpielzÃ¼gen gibt es allerdings $ğ‘ ^r$ SpielzustÃ¤nde und
    ğ‘€ğ‘–ğ‘›ğ‘–ğ‘šğ‘ğ‘¥ hat dann eine Laufzeit von $ğ‘‚(ğ‘ ^r)$.
    <br>
    <br>

    Bei kleinen, simplen Spielen mag diese Laufzeit nicht zum Problem werden.
    Betrachtet man aber ein komplexeres Spiel wie Schach sieht das anders aus.
    Hier
    gibt es bei einem durchschnittlichen Spiel ca. 100 Runden mit
    durchschnittlich
    ca. 35 mÃ¶glichen SpielzÃ¼gen. Es gibt also $35^{100} â‰ˆ 10^{154}$ Knoten im
    Spielbaum.
    Hier kann, wenn dynamische Programmierung verwendet wird, noch ein wenig
    optimiert werden, indem gleiche SpielzustÃ¤nde, die Ã¼ber verschiedene
    Sequenzen
    von SpielzÃ¼gen erreicht werden kÃ¶nnen, zusammengefasst werden. Doch selbst
    dann
    gibt es immer noch ca. $10^{40}$ verschiedene SpielzustÃ¤nde.
    <br>
    <br>

    Auch mit Optimierung kÃ¶nnen von einer KI, die zeitbeschrÃ¤nkt den besten Zug
    bestimmen soll, nicht alle mÃ¶glichen SpielzustÃ¤nde evaluiert werden.
    Stattdessen
    wird der Spielbaum bis zu einer festgelegten Tiefe generiert. Der Nutzen der
    so
    entstandenen Blattknoten wird dann abgeschÃ¤tzt. Allerdings leidet darunter
    natÃ¼rlich das Ergebnis, da es sehr schwierig ist, diesen Nutzen
    abzuschÃ¤tzen.
    <br>

    <h3>Alpha-Beta-Pruning</h3>

    <p>
      Abhilfe schaffen kann da eine weitere
      Optimierung: das <b>Alpha-Beta-Pruning</b>.
      DafÃ¼r schauen wir uns unser Beispiel von Aufgabe 1 nochmals an. Diesmal
      wollen
      wir allerdings genauer Ã¼berlegen, was wir Ã¼ber den Wert eines Knotens
      wissen,
      wÃ¤hrend seine Kindknoten ausgewertet werden.
    </p>
  </p>

  <div class="slides">
    <div class="slide">
      <div class="slide-content">
        <img src="ab1.png" alt="Abbildung 1 des prunings">
        <p>
          Noch nicht betrachtete Teile des Baums sind ausgegraut. FÃ¼r jeden
          Knoten wird
          sich gemerkt, wie groÃŸ sein Wert maximal und minimal sein kann. Diese
          Werte
          werden in den Intervallklammern dargestellt. Da Knoten E einen Wert
          von
          9 hat
          und Knoten B ein ğ‘€ğ¼ğ‘-Knoten ist, wissen wir, dass der Wert von B
          maximal 9 sein
          wird.
        </p>
      </div>
    </div>
    <div class="slide">
      <div class="slide-content">
        <img src="ab2.png" alt="Abbildung 1 des prunings">
        <p>
          Als nÃ¤chstes wird Knoten F betrachtet. Er hat einen Wert von 9. Das
          Ã¤ndert fÃ¼r
          Knoten B nichts, da 9 bereits die obere Grenze ist.
        </p>
      </div>
    </div>
    <div class="slide">
      <div class="slide-content">
        <img src="ab3.png" alt="Abbildung 1 des prunings">
        <p>
          Nun kommt der letzte Kindknoten von B hinzu. Dieser hat einen Wert von
          7. Da B
          ein ğ‘€ğ¼ğ‘-Knoten ist, wird 7 gegenÃ¼ber der vorherigen oberen Grenze 9
          bevorzugt.
          Da auÃŸerdem kein weiterer Kindknoten dazukommt, steht die 7 nun auch
          als
          untere
          Grenze fÃ¼r Knoten B fest. Damit ist dann auch die untere Grenze von
          Knoten A
          klar 7, da A ein ğ‘€ğ´ğ‘‹-Knoten ist und keine kleineren Werte als 7
          gewÃ¤hlt
          werden
          wÃ¼rden.
        </p>
      </div>
    </div>
    <div class="slide">
      <div class="slide-content">
        <img src="ab4.png" alt="Abbildung 1 des prunings">
        <p>
          Als nÃ¤chstes wird H betrachtet. H hat einen Wert von 4, also gilt fÃ¼r
          den
          darÃ¼ber liegenden ğ‘€ğ¼ğ‘-Knoten C die obere Grenze von 4. Da A bereits
          eine
          untere
          Grenze von 7 hat, ist C damit unabhÃ¤ngig von I und J fÃ¼r A nicht mehr
          interessant. I und J mÃ¼ssen also gar nicht mehr betrachtet werden.
          Dies
          wird
          Pruning genannt.
        </p>
      </div>
    </div>
    <div class="slide">
      <div class="slide-content">
        <img src="ab5.png" alt="Abbildung 1 des prunings">
        <p>
          Nun wird K betrachtet. K hat einen Wert von 9. Also hat der darÃ¼ber
          liegende
          ğ‘€ğ¼ğ‘-Knoten D 9 als obere Grenze. 9 wÃ¤re fÃ¼r A aber interessant, da
          9
          grÃ¶ÃŸer als
          7 ist. Also mÃ¼ssen weitere Kinder von D betrachtet werden. Da nun fÃ¼r
          alle
          Kinder von A eine obere Grenze feststeht, hat auch A nun eine obere
          Grenze.
        </p>
      </div>
    </div>
    <div class="slide">
      <div class="slide-content">
        <img src="ab6.png" alt="Abbildung 1 des prunings">
        <p>
          Als nÃ¤chstes wird also L betrachtet. Damit bekommt D eine obere Grenze
          von 5,
          ist also wegen der unteren Grenze von A fÃ¼r A nicht mehr relevant. Das
          letzte
          Kind von D braucht also nicht mehr betrachtet werden. FÃ¼r A steht nun
          der exakte
          Wert 7 fest.
        </p>
      </div>
    </div>

    <div id="slide-number"></div>

    <button class="slide-button-left" onclick="plusDivs(-1)">&#10094;</button>
    <button class="slide-button-right" onclick="plusDivs(1)">&#10095;</button>
  </div>
  <br>
  <p>
    <i>Alpha-Beta-Pruning</i> ist also prinzipiell immer noch ğ‘€ğ‘–ğ‘›ğ‘–ğ‘šğ‘ğ‘¥,
    allerdings
    werden zusÃ¤tzlich zwei Variablen ğ›¼ und ğ›½ verwendet, um die obere und
    untere
    Grenze fÃ¼r das Ergebnis eines jeden Knotens zu speichern. Dadurch kÃ¶nnen
    uninteressante TeilbÃ¤ume frÃ¼her ignoriert werden. In unserem Beispiel
    konnten
    3
    TeilbÃ¤ume geprunt werden. Das mag auf den ersten Blick nicht gerade viel
    erscheinen, aber wenn komplexere Spiele wie Schach betrachtet werden,
    kÃ¶nnen
    hÃ¤ufig deutlich mehr TeilbÃ¤ume mit viele grÃ¶ÃŸerer Tiefe geprunt werden und
    somit
    einiges an der Performance verbessert werden.

    <br>
    <h3>Move Ordering</h3>
    Was auffallen sollte ist, dass die Reihenfolge, in der die SpielzÃ¼ge
    ausgewertet
    werden, nun enorm wichtig ist. Denn wenn zum Beispiel Knoten H und I
    vertauscht
    wÃ¤ren, dann kÃ¶nnte I nicht geprunt werden, weil Schritt 4 Knoten C eine
    obere
    Grenze von 8 hÃ¤tte und somit fÃ¼r A noch interessant wÃ¤re. Auf der anderen
    Seite
    wÃ¤re eine Vertauschung von K und L sehr wÃ¼nschenswert, da dann K geprunt
    werden
    kÃ¶nnte, weil schon in Schritt 5 die obere Grenze von 5 fÃ¼r D feststehen
    wÃ¼rde.
    Um die SpielzÃ¼ge effizient in eine gute Reihenfolge zu bringen, werden in
    der
    Praxis Heuristiken angewendet. Diese sind natÃ¼rlich sehr vom Spiel
    abhÃ¤ngig.
    <br>
    <br>
    Beim Schach gibt es viele verschiedene Varianten, wie die SpielzÃ¼ge
    vorsortiert
    werden kÃ¶nnen. Wir mÃ¶chten davon nur eine beispielhaft betrachten. Dabei
    werden
    zuerst die ZÃ¼ge betrachtet, die eine gegnerische Figur schlagen. Innerhalb
    dieser ZÃ¼ge wird nochmal weiter sortiert, nÃ¤mlich werden zu erste die ZÃ¼ge
    betrachtet, bei denen die gegnerische Dame geschlagen wird, dann ein
    gegnerischer Turm, ..., und zum Schluss ein gegnerischer Bauer. Als
    nÃ¤chstes
    werden dann die ZÃ¼ge betrachtet, die eine gegnerische Figur bedrohen, also
    die
    MÃ¶glichkeit schaffen, im nÃ¤chsten Zug zu schlagen. Auch hier wird die
    gleiche
    innere Reihenfolge verwendet. Alle restlichen ZÃ¼ge werden nur noch zuerst
    in
    vorwÃ¤rts und dann in rÃ¼ckwÃ¤rts Bewegungen eingeteilt. Diese einfache
    Heuristik
    kann die KI schon deutlich verbessern.
    <br>
    <br>
    <p>
      Mit einer guten Heuristik, wie dem Beispiel vom Schach, kann die Anzahl
      der
      SpielzÃ¼ge die pro Knoten ausgewertet werden mÃ¼ssen von ğ‘  auf ca.
      $\sqrt{s}$
      verringert werden.
    </p>
  </p>

  <details class="aufgabe">
    <summary>Aufgabe 2</summary>
    <div class="content">

      <p>Wie verÃ¤ndert das die Laufzeit und was hat das fÃ¼r eine Auswirkung
        auf
        die
        Schach-KI, wenn weiterhin die gleiche Zeit fÃ¼r die Berechnung des
        nÃ¤chsten Zugs
        zur VerfÃ¼gung steht?
      </p>

    </div>
  </details>
  <details class="aufgabe">
    <summary>LÃ¶sung der Aufgabe 2</summary>
    <div class="content">

      <p>Die Laufzeit verÃ¤ndert sich von $O(s^r)$ auf ca.
        $O(\sqrt{s}^r) = O(s^{\frac{r}{2}})$.
        Der
        Exponent kann
        also etwa halbiert werden. Dadurch kann die Schach-KI in der gleichen
        Zeit den
        Baum doppelt so tief generieren und somit deutlich bessere Ergebnisse
        liefern,
        da die SchÃ¤tzungen fÃ¼r die Blattknoten deutlich verbessert werden
        kÃ¶nnen.
      </p>

    </div>
  </details>

  <br>
  <br>
  <p>Im nÃ¤chsten Abschnitt analysieren wir ein Spiel, bei dem es sich nicht um
    ein Zero-sum-game handelt und finden heraus, was hier die beste Strategie
    ist.</p>

  <h2>2. Prisoners Dilemma</h2>
  <h3>Klassische Prisoners Dilemma</h3>
  <div class="text-with-image">
    <div>
      <p>
        Kontext: Zwei Gefangene werden beschuldigt gemeinsam ein Verbrechen
        begangen zu haben. Die beiden Gefangenen werden einzeln verhÃ¶rt und
        haben
        nicht die MÃ¶glichkeit miteinander zu kommunizieren. Jeder der beiden
        Gefangenen hat nun zwei MÃ¶glichkeiten: leugnen oder gestehen. <br>
      </p>
      Rechts befindet sich die Pay-Off-Matrix, die den Nutzen der jeweiligen
      <b>Strategie</b>
      (leugnen, oder gestehen) enthÃ¤lt. Der Nutzen entspricht den Jahren, die
      ein Gefangener im GefÃ¤ngnis absitzen muss.
    </div>
    <div class="table-container">
      <table>
        <tr>
          <td></td>
          <td>B: leugnen</td>
          <td>B: gestehen</td>
        </tr>
        <tr>
          <td>
            A:leugnen
          </td>
          <td>A: -1 | B: -1</td>
          <td>A: -10 | B: 0</td>
        </tr>
        <tr>
          <td>
            A:gestehen
          </td>
          <td>A: 0 | B: -10</td>
          <td>A: -5 | B: -5</td>
        </tr>
      </table>
      <p> <i>Abb: Prisoners Dilemma Pay-Off-Matrix</i></p>
    </div>
  </div>

  <details class="aufgabe">
    <summary>Aufgabe 3</summary>
    <div class="content">
      Wie wÃ¼rdest du handeln? WÃ¼rdest du leugnen, oder gestehen?
    </div>
  </details>
  <details class="aufgabe">
    <summary>LÃ¶sung der Aufgabe 3</summary>
    <div class="content">
      Ein rationaler Spieler, genannt Agent, wÃ¼rde gestehen. Um dies zu
      erlÃ¤utern schauen wir uns die
      optimale Strategie von Spieler B an. Wenn A gesteht, ist es fÃ¼r Spieler B
      besser zu gestehen, da er dann frei kommt, wohingegen er, wenn er leugnen
      wÃ¼rde 1 Jahr lang ins GefÃ¤ngnis mÃ¼sste. Wenn A leugnet, ist es fÃ¼r Spieler
      B ebenfalls besser zu gestehen, weil er dann nur 5 Jahre, anstatt 10 Jahre
      ins GefÃ¤ngnis muss. Da dies eine vollstÃ¤ndige Fallunterscheidung ist, ist
      es fÃ¼r Spieler B immer besser zu gestehen.
    </div>
  </details>
  <br>
  <p>Hier noch ein paar weitere Begriffe:</p>

  <p>
    Eine <b>dominante Strategie</b> ist eine Strategie, die unter allen
    mÃ¶glichen Strategien den hÃ¶chsten Nutzen
    bietet, unabhÃ¤ngig davon, was die anderen Akteure tun. Dementsprechend ist
    die dominante Strategie beim Prisoners Dilemma zu gestehen.
  </p>

  <p>
    Ein <a href="https://de.wikipedia.org/wiki/Nash-Gleichgewicht"
      target="_blank"><b>Nash-Equilibrium</b></a> ist eine Kombination aus
    Strategien, wobei
    jeder Spieler genau eine Strategie wÃ¤hlt, von der aus es fÃ¼r keinen
    Spieler sinnvoll ist, von der gewÃ¤hlten Strategie abzuweichen.
  </p>
  <p>
    Das Nash-Equilibrium besteht beim Prisoners Dilemma in der Kombination aus
    Strategien, bei der beide gestehen.
  </p>
  <p>
    Das Dilemma besteht darin, dass der aufaddierte Nutzen der beiden Spieler
    im Nash-Equilibrium (-10) schlechter ist, als wenn beide leugnen (-2).
  </p>

  <h3>Alltagsbeispiele</h3>
  <p>
    Das Prisoners Dilemma tritt im Alltag in vielen Situationen, fern von
    GefÃ¤ngnissen auf. Schauen wir uns das Beispiel von Werbung an. Stellen wir
    uns also zwei Unternehmen vor, die beide gleich gutes Waschmittel verkaufen
    mÃ¶chten.
    Wenn beide Unternehmen keine Werbung machen, haben beide Unternehmen keine
    Ausgaben fÃ¼r Werbung und wir kÃ¶nnen davon ausgehen, dass ungefÃ¤hr 50% der
    Kunden
    das Waschmittel vom Unternehmen 1 kaufen und 50% das des Unternehmens 2.
    Wenn nun genau ein Unternehmen Werbung schaltet, dann kÃ¶nnen wir uns
    vorstellen, dass mehr Leute das Waschmittel dieses Unternehmens kaufen
    wÃ¼rden. Wenn beide Unternehmen Werbung schalten, dann haben wir wieder die
    selbe Kundenverteilung, wie wenn kein Unternehmen Werbung schaltet. <br>
    Die dominante Strategie besteht also darin Werbung zu schalten. Somit
    befindet sich das
    Nash-Equilibrium darin, dass beide Unternehmen Werbung schalten, wodurch sie
    ihre Ausgaben erhÃ¶hen, ohne die Einnahmen im Vergleich zu der Situation, wo
    beide Unternehmen keine Werbung bezahlen zu steigern.
    <br>
    <br>
    Weitere Beispiele sind:
  </p>
  <ul class="ul">
    <li>Nationen, die Atomwaffen lagern</li>
    <li>Athleten, die Drogen zur Leistungsverbesserung nehmen</li>
    <li>Ãœberfischung </li>
    <li><a
        href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma#Real-life_examples"
        target="_blank">Weitere Beispiele</a></li>
  </ul>

  <br>

  <h3>Prisoners Dilemma mit einer Endlichen Rundenanzahl</h3>

  <p>
    Stellen wir uns nun vor, dass beiden Spielern gesagt wird, dass das Spiel
    100 mal wiederholt wird. Werden die beiden Spieler nun ihre Strategie
    Ã¤ndern, um kÃ¼rzer ins GefÃ¤ngnis gehen zu mÃ¼ssen?
  </p>

  <details class="aufgabe">
    <summary>Aufgabe 4</summary>
    <div class="content">
      Beweise, dass zwei rationale Agenten
      weiterhin in jeder Runde gestehen werden.
    </div>
  </details>

  <details class="aufgabe">
    <summary>LÃ¶sung Aufgabe 4</summary>
    <div class="content">
      <p>
        <!-- Ausklappbar -->
        <!-- Noch mal drÃ¼ber nachdenken, bezÃ¼glich der gewinnen und siegen Geschichte -->
        LÃ¶sung: Der Beweis funktioniert per <a
          href="https://de.wikipedia.org/wiki/RÃ¼ckwÃ¤rtsinduktion"
          target="_blank">RÃ¼ckwÃ¤rtsinduktion</a>.
        <br />
        Am 100. Tag hat die Entscheidung der beiden Spieler
        keinen Einfluss auf weitere Spielrunden. Ein rationaler Agent wÃ¼rde nun
        also
        lediglich versuchen den fÃ¼r sich grÃ¶ÃŸten Nutzen rauszuziehen, indem er
        gesteht. Wir befinden uns schlieÃŸlich in der selben Situation, wie wenn
        das Prisoners Dilemma nur ein Mal gespielt wird, also wie im klassischen
        Prisoners Dilemma.
        <br />
        Nun gilt aber fÃ¼r den 99. Tag, dass dieser ebenfalls keine Auswirkung
        auf weitere Tage hat, da am 100. Tag schon klar ist, wie wir handeln.
        Somit wird jeder Agent auch am 99. Tag optimal fÃ¼r sich handeln, indem
        er gesteht.
        <br>
        Das Verfahren setzt sich bis zum 1. Tag fort und wir kommen zu dem
        Ergebnis, dass ratinale Spieler immer gestehen wÃ¼rden.
      </p>
    </div>
  </details>

  <h3>Prisoners Dilemma mit einer "unendlichen" Rundenanzahl</h3>

  <p>
    Nun wird den beiden Angeklagten nicht von Anfang an gesagt wie viele
    Runden sie spielen werden. Stattdessen wird ihnen gesagt, dass sie nach
    jeder Runde mit einer Wahrscheinlichkeit von 99% noch eine weitere Runde
    spielen. Der Erwartungswert fÃ¼r die Rundenanzahl liegt somit immer noch bei
    100 Runden.
  </p>
  <p>
    Werden die Spieler nun ihr Verhalten verÃ¤ndern um kÃ¼rzer ins GefÃ¤ngnis zu
    mÃ¼ssen?
  </p>
  <p>
    Das kommt darauf an, was man optimieren mÃ¶chte. Man unterscheidet zwischen
    <b>Siegen</b> und <b>Gewinnen</b>. <br />
    Beim Siegen geht es einem Spieler darum kÃ¼rzer als, oder gleich lang wie der
    Gegenspieler ins
    GefÃ¤ngnis gehen zu
    mÃ¼ssen. <br />
    Beim Gewinnen geht es einem Spieler darum mÃ¶glichst kurz ins GefÃ¤ngnis zu
    mÃ¼ssen.
  </p>
  <br>
  <p>Nun schauen wir uns ein paar dieser Strategien an:</p>

  <h4>Sieger-Strategie - "immer gestehen"</h4>

  Bei der Strategie "immer gestehen" siegt ein Spieler immer gegen den
  anderen.
  Um das zu beweisen, genÃ¼gt es sich den Spieler B, also die rechte Spalte
  anzuschauen.
  Wenn Spieler B gesteht, und A leugnet, muss B kÃ¼rzer ins GefÃ¤ngnis und wenn
  beide gestehen mÃ¼ssen beide gleich lang ins GefÃ¤ngnis. Somit muss muss Spieler
  B, wenn er immer gesteht insgesamt entweder gleich lang, oder kÃ¼rzer als
  Spieler A ins GefÃ¤ngnis. Also siegt Spieler B.

  <div class="table-container">
    <table>
      <tr>
        <td></td>
        <td>B: leugnen</td>
        <td>B: gestehen</td>
      </tr>
      <tr>
        <td>
          A:leugnen
        </td>
        <td>A: -1 | B: -1</td>
        <td>A: <span class="red">-10</span> | B: <span class="green">0</span>
        </td>
      </tr>
      <tr>
        <td>
          A:gestehen
        </td>
        <td>A: 0 | B: -10</td>
        <td>A: <span class="red">-5</span> | B: <span class="green">-5</span>
        </td>
      </tr>
    </table>
    <p> <i>Abb: Prisoners Dilemma Pay-Off-Matrix mit farbiger Hervorhebung
        des
        Nutzens, wenn Spieler B gesteht</i> </p>
  </div>

  <h4>Gewinnoptimierungs-Strategie - "Perpetual Punishment"</h4>
  <p>
    Bei dieser Strategie denkt ein Spieler folgendermaÃŸen: "Ich leugne
    solange, bis der andere gesteht. Ab dann gestehe ich immer."
  </p>

  <div class="table-container center">
    <table>
      <tr>
        <td>
          Random
        </td>
        <td>leugnen <br> -1 </td>
        <td>leugnen <br> -1 </td>
        <td>gestehen <br> 0 </td>
        <td>gestehen <br> -5 </td>
        <td>leugnen <br> -10 </td>
        <td>gestehen <br> -5 </td>
      </tr>
      <tr>
        <td>
          Perpetual Punishment
        </td>
        <td>leugnen <br> -1 </td>
        <td>leugnen <br> -1 </td>
        <td>leugnen <br> -10 </td>
        <td>gestehen <br> -5 </td>
        <td>gestehen <br> 0 </td>
        <td>gestehen <br> -5 </td>
      </tr>
    </table>
    <p> <i>Abb: Veranschaulichung der "Perpetual Punishment" Strategie </i>
    </p>
  </div>

  <div>Diese Strategie kann sehr gut sein, beispielsweise, wenn beide Spieler
    Perpetual Punishment spielen und dementsprechend beide immer leugnen. <br>
    Dann liegt der Erwartungswert (wenn mit einer 99%igen Wahrscheinlichkeit
    eine
    weitere Runde gespielt wird) fÃ¼r jeden Spieler bei:

    <p>

      $$
      \begin{align}
      & \sum_{i=0}^\infty (0.99)^i \cdot (-1) && \\
      = & (-1) \cdot \sum_{i=0}^\infty (0.99)^i && | \mbox{Konstante
      ausklammern}
      \\
      = & (-1) \cdot \frac{1}{1-0.99} && | \mbox{Summe geometrische Reihe}
      \\
      = & -100
      \end{align}
      $$
    </p>


    Wenn Spieler A schon bei der ersten Iteration gesteht, dann liegt der
    Erwartungswert fÃ¼r Spieler B, der die "Perpetual Punishment" Strategie
    spielt bei:
    $$-10 + \sum_{i=1}^\infty (0.99)^i \cdot (-5) = -505$$

    Da diese Strategie nur in bestimmten FÃ¤llen sehr gute Erwartungswerte hat
    und
    in anderen FÃ¤llen sehr schlechte Erwartungswerte hat, ist sie nur eine
    <b>mittelmÃ¤ÃŸige</b> Gewinnoptimierungs-Strategie.

  </div>

  <h4>Gewinnoptimierungs-Strategie - "Tit for Tat"</h4>
  <p>

  </p>

  <p>
    Getreu der Aussage: "Wie du mir, so ich dir.", leugnet ein Spieler, der mit
    der Strategie "<a href="https://de.wikipedia.org/wiki/Tit_for_Tat"
      target="_blank">Tit for Tat</a>" spielt immer in der
    ersten Runde und kopiert in den nÃ¤chsten Runden immer das Verhalten des
    anderen Spielers aus der Runde davor.

    <div class="table-container center">
      <table>
        <tr>
          <td>
            Random
          </td>
          <td>leugnen <br> -1 </td>
          <td>leugnen <br> -1 </td>
          <td>gestehen <br> 0 </td>
          <td>gestehen <br> -5 </td>
          <td>leugnen <br> -10 </td>
          <td>leugnen <br> -1 </td>
        </tr>
        <tr>
          <td>
            Tit for Tat
          </td>
          <td>leugnen <br> -1 </td>
          <td>leugnen <br> -1 </td>
          <td>leugnen <br> -10 </td>
          <td>gestehen <br> -5 </td>
          <td>gestehen <br> 0 </td>
          <td>leugnen <br> -1 </td>
        </tr>
      </table>
      <p> <i>Abb: Veranschaulichung der "Tit for Tat" Strategie </i> </p>
    </div>

    Die Strategie zeichnet sich dadurch aus, dass Spieler A, der diese
    Strategie anwendet:
    <ul class="ul">
      <li>zuerst die <b>Kooperation</b> mit dem Gegenspieler anbietet, so dass
        beide
        Aussichten auf 1 Jahr im GefÃ¤ngnis haben</li>
      <li>den anderen <b>"bestraft"</b>, der gesteht und damit das Leugnen von
        Spieler A
        ausnutzt. A "bestraft" den Gegenspieler, indem er in der nÃ¤chsten
        Runde
        auch gesteht</li>
      <li>sich mit dem anderen Spieler <b>"versÃ¶hnen"</b> kann. Denn wenn
        Spieler
        B wieder leugnet, dann leugnet auch Spieler A wieder und beide haben
        wieder Aussichten auf 1 Jahr im GefÃ¤ngnis</li>
    </ul>
    <br>
    <div>
      Der einzige Fall mit dem "Tit for Tat" Schwierigkeiten hat tritt auf,
      wenn
      beispielsweise beide Spieler "Tit for Tat" spielen und eine <i>StÃ¶rung</i>
      auftritt. Beispielsweise gesteht ein Spieler doch, weil die
      Polizei ihn so sehr unter Druck gesetzt hat. In diesem Fall entsteht ein
      <i>Echo</i>, was sich dadurch auszeichnet, dass Spieler A und B
      abwechselnd
      leugnen und gestehen. Der Erwartungswert verschlechtert sich dann
      drastisch.
    </div>

    <div class="table-container center">
      <table>
        <tr>
          <td>
            Tit for Tat
          </td>
          <td>leugnen <br> -1 </td>
          <td>leugnen <br> -1 </td>
          <td class="red">gestehen <br> 0 </td>
          <td>leugnen <br> -10 </td>
          <td class="red">gestehen <br> 0 </td>
          <td>leugnen <br> -10 </td>
        </tr>
        <tr>
          <td>
            Tit for Tat
          </td>
          <td>leugnen <br> -1 </td>
          <td>leugnen <br> -1 </td>
          <td>leugnen <br> -10 </td>
          <td class="red">gestehen <br> 0 </td>
          <td>leugnen <br> -10 </td>
          <td class="red">gestehen <br> 0 </td>
        </tr>
      </table>
      <p> <i>Abb: Veranschaulichung der "Tit for Tat" Strategie bei einer
          StÃ¶rung
        </i> </p>
    </div>

    <h2>3. Nash-Equilibrium bei gemischten Strategien</h2>

    <p>
      Zum Abschluss betrachten wir die erneut das wichtige Konzept des
      Nash-Equilibriums. Diesmal aber in Verbindung mit gemischten Strategien.
      Wir
      nennen die verschiedenen SpielzÃ¼ge, die ein Spieler in jeder Runde zur
      VerfÃ¼gung
      hat $s_1, ..., s_n$. Bei einer <a
        href="https://de.wikipedia.org/wiki/Reine_Strategie"
        target="_blank"><b>reinen
          Strategie</b></a> spielt der Spieler
      immer den
      gleichen
      Spielzug.
      Eine <a href="https://de.wikipedia.org/wiki/Gemischte_Strategie"
        target="_blank"><b>gemischte Strategie</b></a> besteht aus einer
      Wahrscheinlichkeitsverteilung
      Ã¼ber
      die $s_i$. Jedem $s_i$ wird also eine Wahrscheinlichkeit $p_i$ so
      zugeordnet, dass $\sum_{i=0}^n p_i = 1$ gilt.
      In
      jeder
      Runde wÃ¤hlt der Spieler dann mit den Wahrscheinlichkeiten $p_i$ zufÃ¤llig
      einen der
      SpielzÃ¼ge $s_i$ aus.
      Wir erinnern uns, dass eine <b>Nash-Equilibrium</b> dann vorliegt, wenn es
      sich fÃ¼r
      keinen der Spieler lohnt, seine Strategie zu Ã¤ndern. Bei gemischten
      Strategien
      zÃ¤hlt bereits ein Anpassen der Wahrscheinlichkeitsverteilung als Ã„nderung.
      Es
      lÃ¤sst sich der folgende Satz zeigen:

    </p>

    <br>

    <p>
      <b>Satz von Nash</b>: Erlaubt man gemischte Strategien, so gibt es in
      jedem
      Zero-sum-game ein Nash-Equilibrium.
    </p>

    <br>

    <p>
      AuÃŸerdem gilt der folgende Satz:
    </p>

    <br>

    <p>
      <b>Satz der gleichen Erwartungswerte</b>: In einem Nash-Equilibrium sind
      die
      Erwartungswerte fÃ¼r die verschiedenen SpielzÃ¼ge die ein Spieler in seiner
      gemischten Strategie hat gleich.
    </p>
    <br>
    <p>
      <b>Beweis</b>: Wir fÃ¼hren den Beweis per Widerspruch. Seien die Strategien
      von
      Alice
      und Bob so, dass sie sich in einem Nash-Equilibrium befinden. Nehmen wir
      nun
      an,
      dass die Erwartungswerte der SpielzÃ¼ge die Alice in ihrer Strategie hat
      nicht
      gleich sind. Dann gibt es in der Strategie von Alice zwei SpielzÃ¼ge $s_1,
      s_2$
      so,
      dass der Erwartungswert fÃ¼r Alice, wenn sie $s_1$ spielt, grÃ¶ÃŸer ist als
      der
      Erwartungswert, wenn sie $s_2$ spielt. Da Alice aber rational spielt,
      wÃ¼rde
      sie
      dann aber statt $s_2$ immer $s_1$ spielen. Sie wÃ¼rde also ihre Strategie
      anpassen,
      und damit ihren Erwartungswert steigern. Ein Widerspruch zur Annahme, dass
      sich
      Alice und Bob in einem Nash-Equilibrium befinden. Also kann unsere Annahme
      nur
      falsch sein. Die Erwartungswerte fÃ¼r die verschiedenen SpielzÃ¼ge die ein
      Spieler
      in seiner gemischten Strategie hat mÃ¼ssen also gleich sein. $\blacksquare$

    </p>

    <h3>Rock, Paper, Scissors</h3>

    <p>
      Betrachten wir nun das allen bekannte Spiel Rock, Paper, Scissors.
      Bekanntlich
      besiegt Rock Scissors, Scissors Paper und Paper Rock.
    </p>

    <div class="table-container">
      <table>
        <tr>
          <td></td>
          <td></td>
          <td>$p_{BR}$</td>
          <td>$p_{BP}$</td>
          <td>$p_{BS}$</td>
        </tr>
        <tr>
          <td></td>
          <td></td>
          <td>B: Rock</td>
          <td>B: Paper</td>
          <td>B: Scissors</td>
        </tr>
        <tr>
          <td>$p_{AR}$</td>
          <td>A: Rock</td>
          <td>A: 0 | B: 0</td>
          <td>A: -1 | B: 1</td>
          <td>A: 1 | B: -1</td>
        </tr>
        <tr>
          <td>$p_{AP}$</td>
          <td>A: Paper</td>
          <td>A: 1 | B: -1</td>
          <td>A: 0 | B: 0</td>
          <td>A: -1 | B: 1</td>
        </tr>
        <tr>
          <td>$p_{AS}$</td>
          <td>A: Scissors</td>
          <td>A: -1 | B: 1</td>
          <td>A: 1 | B: -1</td>
          <td>A: 0 | B: 0</td>
        </tr>
      </table>
      <p> <i>Abb: Pay-Off Matrix des Spiels Rock, Paper, Scissors
        </i> </p>
    </div>

    <details class="aufgabe">
      <summary>Aufgabe 5</summary>
      <div class="content">
        Warum gibt es bei Rock, Paper Scissors kein Nash-Equilibrium aus reinen
        Strategien?
      </div>
    </details>
    <details class="aufgabe">
      <summary>LÃ¶sung der Aufgabe 5</summary>
      <div class="content">
        Jede reine Strategie kann durch eine andere reine Strategie besiegt
        werden.
        Somit kann bei jeder Kombination aus reinen Strategien einer der Spieler
        reagieren um sich zu verbessern.
      </div>
    </details>

    <p>
      Nach dem Satz von Nash muss es aber ein Nash-Equilibrium mit gemischten
      Strategien geben. Dieses wollen wir nun berechnen. DafÃ¼r benennen wir die
      Wahrscheinlichkeiten mit denen die beiden Spieler die verschiedenen
      SpielzÃ¼ge
      wÃ¤hlen. Beispielsweise steht $p_{AR}$ fÃ¼r die Wahrscheinlichkeit, dass
      Spieler A
      Rock spielt und $p_{BS}$ dafÃ¼r, dass Spieler B Scissors
      spielt. Um diese Wahrscheinlichkeiten zu berechnen nutzen wir den Satz der
      gleichen Erwartungswerte. Demnach gilt nÃ¤mlich, dass $E_A[Rock]$ (der
      Erwartungswert fÃ¼r Spieler A,
      wenn er Rock spielt), $E_A[Paper]$ und $E_A[Scissors]$ gleich sind.
    </p>
    <br>
    <p>Die Erwartungswerte fÃ¼r A kÃ¶nnen wir leicht mit den Ergebnissen von A und
      den
      Wahrscheinlichkeiten von B berechnen.</p>
    <br>
    <p>
      $$
      \begin{align}
      E_A[Rock] &= 0\cdot p_{BR} - 1\cdot p_{BP} + 1\cdot p_{BS}\\
      E_A[Paper] &= 1\cdot p_{BR} + 0\cdot p_{BP} - 1\cdot p_{BS}\\
      E_A[Scissors] &= -1\cdot p_{BR} + 1\cdot p_{BP} + 0\cdot p_{BS}
      \end{align}
      $$
    </p>
    <p>
      Nun kÃ¶nnen wir $E_A[Rock]$ mit $E_A[Paper]$ und $E_A[Scissors]$
      gleichsetzen:
    </p>
    <p>
      $$
      \begin{align}
      0\cdot p_{BR} - 1\cdot p_{BP} + 1\cdot p_{BS} &= 1\cdot p_{BR} + 0\cdot
      p_{BP} -
      1\cdot p_{BS}\\
      0\cdot p_{BR} - 1\cdot p_{BP} + 1\cdot p_{BS} &= -1\cdot p_{BR} + 1\cdot
      p_{BP}
      + 0\cdot p_{BS}
      \end{align}
      $$
    </p>
    <p>
      Zusammen mit der Eigenschaft, dass die Wahrscheinlichkeiten $p_{BR},
      p_{BP},
      p_{BS}$ zusammen $1$ ergeben mÃ¼ssen, ergibt sich das folgende lineare
      Gleichungssystem:
    </p>
    <p>
      $$
      \begin{align}
      -1p_{BR} - 1p_{BP} + 2p_{BS} &= 0\\
      1p_{BR} - 2p_{BP} + 1p_{BS} &= 0\\
      1p_{BR} + 1p_{BP} + 1p_{BS} &= 1
      \end{align}
      $$
    </p>
    <p>
      Aus diesem Gleichungssystem ergibt sich $p_{BR} = p_{BP} = p_{BS} =
      \frac{1}{3}$. Ã„quivalent ergibt sich aus $E_B[Rock] = E_B[Paper] =
      E_B[Scissors]$ fÃ¼r die Wahrscheinlichkeiten von A $p_{AR} = p_{AP} =
      p_{AS}
      =
      \frac{1}{3}$.
    </p>
    <br>
    <p>
      Dieses Ergebnis mag wenig Ã¼berraschend sein, da die Pay-Off-Matrix von
      Rock,
      Paper, Scissors symmetrisch ist. Interessanter wird das ganze bei einer
      asymmetrischen Pay-Off- Matrix.
    </p>

    <h3>Matching Pennies</h3>

    <p>
      Wir betrachten als weiteres Spiel
      Matching
      Pennies. Beide Spieler haben eine MÃ¼nze und kÃ¶nnen entscheiden, ob sie
      Heads
      oder Tails spielen (die MÃ¼nze wird nicht geworfen, sondern jeder Spieler
      entscheidet, mit welcher Seite nach oben er die MÃ¼nze auf den Tisch legt).
      Wenn
      nun beide Spieler das gleiche spielen, dann gewinnt Spieler A und wenn sie
      unterschiedlich spielen, dann gewinnt Spieler B. Die Wahrscheinlichkeiten
      fÃ¼r
      die einzelnen SpielzÃ¼ge benennen wir Ã¤quivalent zum vorherigen Beispiel
      ($p_{AH}$
      ist die Wahrscheinlichkeit dass Spieler A Heads spielt...).
    </p>


    <div class="table-container">
      <table>
        <tr>
          <td></td>
          <td></td>
          <td>$p_{BH}$</td>
          <td>$p_{BT}$</td>
        </tr>
        <tr>
          <td></td>
          <td></td>
          <td>B: Heads</td>
          <td>B: Tails</td>
        </tr>
        <tr>
          <td>$p_{AH}$</td>
          <td>A: Heads</td>
          <td>A: 1 | B: -1</td>
          <td>A: -1 | B: 1</td>
        </tr>
        <tr>
          <td>$p_{AT}$</td>
          <td>A: Tails</td>
          <td>A: -1 | B: 1</td>
          <td>A: 1 | B: -1</td>
        </tr>
      </table>
      <p> <i>Abb: Pay-Off Matrix des Spiels Matching Pennies
        </i> </p>
    </div>

    <details class="aufgabe">
      <summary>Aufgabe 6</summary>
      <div class="content">
        Diese Pay-Off-Matrix ist nun wieder symmetrisch. Was sind die
        Wahrscheinlichkeiten fÃ¼r die Strategien, die das Nash-Equilibrium
        bilden?
      </div>
    </details>
    <details class="aufgabe">
      <summary>LÃ¶sung der Aufgabe 6</summary>
      <div class="content">
        Ã„quivalent zum Rock, Paper, Scissors Beispiel ergibt sich $p_{AH} =
        p_{AT}
        = p_{BH} = p_{BT} = \frac{1}{2}$
      </div>
    </details>

    <p>
      Nun wollen wir aber die Pay-Off-Matrix ein wenig verÃ¤ndern. Spieler A
      gewinnt
      nun 100 Punkte, wenn er mit (ğ»ğ‘’ğ‘ğ‘‘ğ‘ , ğ»ğ‘’ğ‘ğ‘‘ğ‘ ) gewinnt und weiterhin
      nur
      einen Punkt, wenn er mit (ğ‘‡ğ‘ğ‘–ğ‘™ğ‘ , ğ‘‡ğ‘ğ‘–ğ‘™ğ‘ ) gewinnt.

    </p>

    <div class="table-container">
      <table>
        <tr>
          <td></td>
          <td></td>
          <td>$p_{BH}$</td>
          <td>$p_{BT}$</td>
        </tr>
        <tr>
          <td></td>
          <td></td>
          <td>B: Heads</td>
          <td>B: Tails</td>
        </tr>
        <tr>
          <td>$p_{AH}$</td>
          <td>A: Heads</td>
          <td>A: 100 | B: -100</td>
          <td>A: -1 | B: 1</td>
        </tr>
        <tr>
          <td>$p_{AT}$</td>
          <td>A: Tails</td>
          <td>A: -1 | B: 1</td>
          <td>A: 1 | B: -1</td>
        </tr>
      </table>
      <p> <i>Abb: Pay-Off Matrix der Abwandlung des Spiels Matching Pennies
        </i> </p>
    </div>

    <p>
      Genau wie im Rock, Paper, Scissors Beispiel nutzen wir den Satz der
      gleichen
      Erwartungswerte:
    </p>
    <p>
      $$
      \begin{align}
      E_A[Heads] = E_A[Tails]
      \end{align}
      $$
    </p>
    <p>
      Die Erwartungswerte fÃ¼r A kÃ¶nnen wir wieder mit den Ergebnissen von A und
      den Wahrscheinlichkeiten von B berechnen.
    </p>
    <p>
      $$
      \begin{align}
      E_A[Heads] &= 100\cdot p_{BH} - 1\cdot p_{BT}\\
      E_A[Tails] &= -1\cdot p_{BH} + 1\cdot p_{BT}
      \end{align}
      $$
    </p>
    <p>
      Nun kÃ¶nnen wir $E_A[Heads]$ mit $E_A[Tails]$ gleichsetzen:
    </p>
    <p>
      $$
      \begin{align}
      100\cdot p_{BH} - 1\cdot p_{BT} = -1\cdot p_{BH} + 1\cdot p_{BT}
      \end{align}
      $$
    </p>
    <p>
      Zusammen mit der Eigenschaft, dass die Wahrscheinlichkeiten $p_{BH}$ und
      $p_{BT}$ zusammen $1$ ergeben mÃ¼ssen, ergibt sich das folgende lineare
      Gleichungssystem:
    </p>
    <p>
      $$
      \begin{align}
      101p_{BH} - 2p_{BT} &= 0\\
      1p_{BH} + 1p_{BT} &= 1
      \end{align}
      $$
    </p>
    <p>
      Aus diesem Gleichungssystem ergibt sich $p_{BH} = \frac{2}{103}\approx
      1,9\%$
      und $p_{BT} = \frac{101}{103}\approx 98,1\%$. Auch hier ergibt sich
      Ã¤quivalent
      aus $E_B[Heads] = E_B[Tails]$ fÃ¼r die Wahrscheinlichkeiten von A $p_{AH} =
      \frac{2}{103}\approx 1,9\%$ und $p_{AT} = \frac{101}{103}\approx 98,1\%$.
    </p>

    <details class="aufgabe">
      <summary>Aufgabe 7</summary>
      <div class="content">
        $p_{AH} â‰ˆ 1,9%$. Warum spielt Spieler A so selten Heads, obwohl er mit
        Heads
        die
        MÃ¶glichkeit hat 100 Punkte zu machen und mit Tails nur 1 Punkt gewinnen
        kann?
      </div>
    </details>
    <details class="aufgabe">
      <summary>LÃ¶sung der Aufgabe 7</summary>
      <div class="content">
        Das liegt daran, dass Spieler B natÃ¼rlich Angst vor den -100 Punkten bei
        (ğ»ğ‘’ğ‘ğ‘‘ğ‘ , ğ»ğ‘’ğ‘ğ‘‘ğ‘ ) hat und daher sehr hÃ¤ufig Tails spielen wird.
        Das
        kann
        Spieler A dann ausnutzen, indem er auch hÃ¤ufig Tails spielt um dann mit
        (ğ‘‡ğ‘ğ‘–ğ‘™ğ‘ , ğ‘‡ğ‘ğ‘–ğ‘™ğ‘ ) 1 Punkt zu gewinnen. Beide spielen aber immer
        mal
        wieder trotzdem Heads, damit sich der andere nicht darauf verlassen
        kann,
        dass
        immer Tails gespielt wird.
      </div>
    </details>

    <h2>Was haben wir gelernt?</h2>
    <ul class="ul">
      <li>Bei Perfect Information Zero-sum-games kann eine KI mit unbegrenzter
        Zeit dem
        einfachen ğ‘€ğ‘–ğ‘›ğ‘–ğ‘šğ‘ğ‘¥ Algorithmus folgen um die optimale Strategie zu
        spielen.
        Sobald die KI zeitbeschrÃ¤nkt ist, oder das Spiel so komplex wird, dass
        ein
        komplettes Generieren des Spielbaums nicht mehr praktikabel ist, kann
        der
        Baum
        mit Hilfe von <i>Alpha-Beta-Pruning</i> und einer guten
        Move-Ordering-Heuristik
        doppelt
        so tief generiert werden wie ohne.
      </li>
      <li>
        Das Nash-Equilibrium besteht beim klassischen Prisoners Dilemma, aus der
        Kombination <br> <i>(gestehen, gestehen)</i>. Durch eine undefinierte
        Anzahl an
        Wiederholungen des Spiels kann es fÃ¼r Spieler trotzdem sinnvoll sein zu
        leugnen
        um ihren Gewinn zu optimieren.
      </li>
      <li>
        Erlaubt man gemischte Strategien, so gibt es in jedem Zero-sum-game ein
        Nash-Equilibrium.
      </li>
    </ul>

    <h2>Literatur</h2>
    <ul class="ul">
      <li>
        Artificial Intelligence, A Modern Approach, Third Edition - Stuart
        Russel,
        Peter Norvig
      </li>
      <li>
        Introducing Game Theory: A Graphic Guide - Ivan Pastine, Tuvana Pastine,
        Tom
        Humberstone
      </li>
      <li>
        The Joy Of Game Theory: An Introduction To Strategic Thinking - Presh
        Talwalker
      </li>
      <li>
        <a href="https://www.javatpoint.com/ai-adversarial-search"
          target="_blank">Adversarial
          Search - Javatpoint</a>
      </li>
      <li>
        <a href="https://de.wikipedia.org/wiki/Gefangenendilemma"
          target="_blank">Gefangenendilemma
          - Wikipedia
        </a>
      </li>
    </ul>


    <script>
      var slideIndex = 1;
      showDivs(slideIndex);

      function plusDivs(n) {
        showDivs(slideIndex += n);
      }

      function showDivs(n) {
        var i;
        var x = document.getElementsByClassName("slide");
        if (n > x.length) { slideIndex = 1 }
        if (n < 1) { slideIndex = x.length }
        document.getElementById("slide-number").innerText = slideIndex + "\/" + x.length
        for (i = 0; i < x.length; i++) {
          x[i].style.display = "none";
        }
        x[slideIndex - 1].style.display = "block";
      }
    </script>
    <div class="space"></div>
    <footer> </footer>
</body>


</html>
